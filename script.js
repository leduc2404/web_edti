// ====================== DOM ELEMENTS =======================
const videoFileInput = document.getElementById('video-file');
const startBtn = document.getElementById('start-btn');
const statusDiv = document.getElementById('status');
const logOutput = document.getElementById('log-output');
const resultSection = document.getElementById('result-section');
const downloadLink = document.getElementById('download-link');

// ====================== CONFIG =======================
let config = {};

// ====================== FFmpeg INIT =======================
const { createFFmpeg, fetchFile } = FFmpeg;
const ffmpeg = createFFmpeg({
  log: true,
  corePath: 'https://unpkg.com/@ffmpeg/core@0.10.0/dist/ffmpeg-core.js',
});

// Log ti·ªán d·ª•ng
const log = (message) => {
  logOutput.textContent += message + '\n';
  logOutput.scrollTop = logOutput.scrollHeight;
};
ffmpeg.setLogger(({ message }) => log(`[FFMPEG] ${message}`));
const setStatus = (message) => (statusDiv.textContent = `Tr·∫°ng th√°i: ${message}`);

// ====================== MODULES =======================

// 1) G·ªçi Gemini qua REST API
async function generateCaptionFromVideo(videoFile, apiKey) {
  log("\n--- B∆Ø·ªöC 1: ƒêang t·∫°o caption b·∫±ng Google Gemini (REST API) ---");
  if (!apiKey) throw new Error("Thi·∫øu Google Gemini API Key trong config.json.");

  const prompt =
    "H√£y vi·∫øt cho t√¥i m·ªôt c√¢u hook b√°n h√†ng ng·∫Øn g·ªçn, h·∫•p d·∫´n, b·∫±ng ti·∫øng Vi·ªát, ƒë·ªô d√†i trong kho·∫£ng 25‚Äì35 ch·ªØ, kh√¥ng ƒë∆∞·ª£c qu√° √≠t. N·ªôi dung nh·∫•n m·∫°nh s·ª± c·∫ßn thi·∫øt c·ªßa s·∫£n ph·∫©m, mang phong c√°ch tr·∫ª trung, d·ªÖ g√¢y ch√∫ √Ω tr√™n m·∫°ng x√£ h·ªôi, b·∫Øt trend. Ch·ªâ xu·∫•t ra duy nh·∫•t vƒÉn b·∫£n th√¥, kh√¥ng ƒë∆∞·ª£c th√™m icon, ti√™u ƒë·ªÅ hay nh·∫Øc nh·ªü.";

  // Chuy·ªÉn video sang base64
  const videoBase64 = await new Promise((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => resolve(reader.result.split(',')[1]);
    reader.readAsDataURL(videoFile);
  });

  // G·ªçi API REST
  const response = await fetch(
    "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=" + apiKey,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              { text: prompt },
              { inlineData: { data: videoBase64, mimeType: videoFile.type } }
            ]
          }
        ]
      }),
    }
  );

  if (!response.ok) throw new Error(`Gemini API l·ªói: ${response.status} ${response.statusText}`);
  const data = await response.json();

  const text = data?.candidates?.[0]?.content?.parts?.[0]?.text?.trim();
  if (!text) throw new Error("Gemini kh√¥ng tr·∫£ v·ªÅ caption: " + JSON.stringify(data));

  log(`T·∫°o caption th√†nh c√¥ng: '${text}'`);
  return text;
}

// 2) Text ‚Üí Audio (FPT.AI)
async function generateAudioFromText(text, apiKey) {
  log("\n--- B∆Ø·ªöC 2: ƒêang t·∫°o audio b·∫±ng FPT.AI TTS ---");
  if (!apiKey) throw new Error("Thi·∫øu FPT.AI API Key trong config.json.");

  const ttsSettings = { voice: "banmai", speed: 1.2, max_retries: 10, retry_delay: 2000 };
  const headers = { 'api-key': apiKey, 'voice': ttsSettings.voice, 'speed': String(ttsSettings.speed) };

  log("G·ª≠i y√™u c·∫ßu t·∫°o audio ƒë·∫øn FPT.AI...");
  const initialResponse = await fetch("https://api.fpt.ai/hmi/tts/v5", {
    method: 'POST', headers, body: text
  });
  if (!initialResponse.ok) throw new Error(`FPT.AI API error: ${initialResponse.statusText}`);

  const data = await initialResponse.json();
  const asyncLink = data.async;
  if (!asyncLink) throw new Error(`FPT.AI kh√¥ng tr·∫£ v·ªÅ link t·∫£i: ${JSON.stringify(data)}`);

  log("Y√™u c·∫ßu th√†nh c√¥ng! ƒêang ch·ªù t·∫£i audio...");
  for (let i = 0; i < ttsSettings.max_retries; i++) {
    await new Promise(r => setTimeout(r, ttsSettings.retry_delay));
    log(`ƒêang th·ª≠ t·∫£i audio l·∫ßn ${i + 1}/${ttsSettings.max_retries}...`);
    const audioResponse = await fetch(asyncLink);
    if (audioResponse.ok) {
      log("T·∫£i audio th√†nh c√¥ng!");
      const audioBlob = await audioResponse.blob();

      // Chuy·ªÉn mp3 ‚Üí wav
      ffmpeg.FS('writeFile', 'temp_tts.mp3', await fetchFile(audioBlob));
      await ffmpeg.run('-i', 'temp_tts.mp3', 'temp_tts.wav');
      const wavData = ffmpeg.FS('readFile', 'temp_tts.wav');
      return new Blob([wavData.buffer], { type: 'audio/wav' });
    }
  }
  throw new Error("H·∫øt th·ªùi gian ch·ªù, kh√¥ng th·ªÉ t·∫£i file audio t·ª´ FPT.AI.");
}

// 3) Gh√©p video b·∫±ng FFmpeg
async function combineVideoWithFFmpeg(videoFile, audioBlob, captionText, overlayFile, fontFile, logoFile) {
  log("\n--- B∆Ø·ªöC 3: ƒêang gh√©p c√°c th√†nh ph·∫ßn b·∫±ng FFmpeg ---");

  // N·∫°p file
  ffmpeg.FS('writeFile', 'input.mp4', await fetchFile(videoFile));
  ffmpeg.FS('writeFile', 'tts.wav', await fetchFile(audioBlob));
  ffmpeg.FS('writeFile', 'overlay.png', await fetchFile(overlayFile));
  ffmpeg.FS('writeFile', 'logo.png', await fetchFile(logoFile));
  ffmpeg.FS('writeFile', 'font.otf', await fetchFile(fontFile));

  // Chu·∫©n b·ªã caption
  const WRAP_AFTER_CHARS = 30;
  const LINE_SPACING = 11;
  const wrapText = (text, maxChars) => {
    const words = text.split(' ');
    let lines = [], line = "";
    for (const w of words) {
      if (!line) line = w;
      else if (line.length + 1 + w.length <= maxChars) line += " " + w;
      else { lines.push(line); line = w; }
    }
    if (line) lines.push(line);
    return lines.join('\n');
  };
  const textWrapped = wrapText(captionText.toUpperCase(), WRAP_AFTER_CHARS);
  const textEscaped = textWrapped.replace(/'/g, `''`).replace(/:/g, `\\:`);

  const filter_complex = `
    [1][0]scale2ref=w=iw:h=ih[ovl][base];
    [ovl]format=rgba[ovl];
    [base][ovl]overlay=0:0[bg];
    [3]scale=200:-1[logo];
    [bg]drawtext=fontfile=/font.otf:text='${textEscaped}':fontsize=33:fontcolor=white:
        borderw=2:bordercolor=black@0.6:line_spacing=${LINE_SPACING}:
        x=(w-text_w)/2:y=(h-text_h)*0.82:text_shaping=1[bgtext];
    [bgtext][logo]overlay=x=W-w-30:y=H*0.68-h[final_v]
  `.replace(/\s+/g, ' ');

  log("B·∫Øt ƒë·∫ßu ch·∫°y FFmpeg ƒë·ªÉ gh√©p video...");
  await ffmpeg.run(
    '-i', 'input.mp4',
    '-i', 'overlay.png',
    '-i', 'tts.wav',
    '-i', 'logo.png',
    '-filter_complex', filter_complex,
    '-map', '[final_v]',
    '-map', '2:a',
    '-c:v', 'libx264', '-preset', 'fast', '-crf', '22',
    '-c:a', 'aac', '-b:a', '192k',
    '-pix_fmt', 'yuv420p',
    '-shortest',
    'output.mp4'
  );

  log("Gh√©p video th√†nh c√¥ng!");
  const data = ffmpeg.FS('readFile', 'output.mp4');
  return new Blob([data.buffer], { type: 'video/mp4' });
}

// ====================== MAIN FLOW =======================
async function startProcessing() {
  startBtn.disabled = true;
  logOutput.textContent = '';
  resultSection.classList.add('hidden');
  setStatus('ƒêang kh·ªüi t·∫°o...');

  try {
    const videoFile = videoFileInput.files[0];
    if (!videoFile) throw new Error("Vui l√≤ng ch·ªçn m·ªôt video ƒë·ªÉ x·ª≠ l√Ω.");

    if (!ffmpeg.isLoaded()) {
      log("ƒêang t·∫£i FFmpeg core... (ch·ªâ l·∫ßn ƒë·∫ßu)");
      await ffmpeg.load();
    }

    setStatus("ƒêang t·∫£i assets...");
    const [overlayFile, logoFile, fontFile] = await Promise.all([
      fetch(config.asset_paths.overlay).then(res => res.blob()),
      fetch(config.asset_paths.logo).then(res => res.blob()),
      fetch(config.asset_paths.font).then(res => res.blob()),
    ]);
    log("T·∫£i assets th√†nh c√¥ng!");

    setStatus('ƒêang t·∫°o caption...');
    const caption = await generateCaptionFromVideo(videoFile, config.api_keys.google_gemini);

    setStatus('ƒêang t·∫°o audio...');
    const audioBlob = await generateAudioFromText(caption, config.api_keys.fpt_ai);

    setStatus('ƒêang gh√©p video...');
    const resultBlob = await combineVideoWithFFmpeg(videoFile, audioBlob, caption, overlayFile, fontFile, logoFile);

    log("\nüéâ HO√ÄN T·∫§T! üéâ");
    setStatus('Ho√†n th√†nh!');
    const url = URL.createObjectURL(resultBlob);
    downloadLink.href = url;
    downloadLink.download = `final_video_${Date.now()}.mp4`;
    resultSection.classList.remove('hidden');
  } catch (error) {
    log(`\n--- L·ªñI ---`);
    log(error.message);
    console.error(error);
    setStatus(`ƒê√£ x·∫£y ra l·ªói. Xem console (F12) ƒë·ªÉ bi·∫øt chi ti·∫øt.`);
  } finally {
    startBtn.disabled = false;
  }
}

// ====================== INIT =======================
document.addEventListener('DOMContentLoaded', async () => {
  try {
    const response = await fetch('config.json');
    if (!response.ok) throw new Error(`Kh√¥ng th·ªÉ t·∫£i config.json (status: ${response.status})`);
    config = await response.json();

    if (!config.api_keys || !config.asset_paths) {
      throw new Error("C·∫•u tr√∫c config.json kh√¥ng h·ª£p l·ªá.");
    }

    log("T·∫£i config.json th√†nh c√¥ng. S·∫µn s√†ng.");
    setStatus("S·∫µn s√†ng");
    startBtn.textContent = "‚ñ∂ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω";
    startBtn.disabled = false;
  } catch (error) {
    log(`L·ªñI KH·ªûI T·∫†O: ${error.message}`);
    setStatus("L·ªói t·∫£i c·∫•u h√¨nh!");
    startBtn.textContent = "L·ªói c·∫•u h√¨nh";
  }
});

startBtn.addEventListener('click', startProcessing);
